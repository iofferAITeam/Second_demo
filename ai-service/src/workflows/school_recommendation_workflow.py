"""
ç»Ÿä¸€çš„6-Agentå­¦æ ¡æ¨èå·¥ä½œæµ
ç®€åŒ–è°ƒåº¦ï¼Œé¿å…æ— é™å¾ªç¯ï¼Œç¡®ä¿å®Œæ•´çš„æ¨èæµç¨‹
"""
import asyncio
import time
from typing import Dict, Any, Optional
from datetime import datetime

from autogen_agentchat.ui import Console
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination
from autogen_agentchat.agents import UserProxyAgent

from src.agents.school_rec_agents import (
    get_summary_agent,
    get_graduate_school_research_agent,
    get_undergraduate_school_research_agent,
    get_final_recommendation_agent,
    get_program_recommendation_agent,
    get_final_school_analysis_agent
)


class SchoolRecommendationWorkflow:
    """
    ç»Ÿä¸€çš„å­¦æ ¡æ¨èå·¥ä½œæµç®¡ç†å™¨
    æŒ‰é¡ºåºè°ƒåº¦6ä¸ªagentå®Œæˆå®Œæ•´çš„æ¨èæµç¨‹
    """

    def __init__(self):
        self.workflow_id = f"school_rec_{int(time.time())}"
        self.agents = self._initialize_agents()
        print(f"ğŸ“ åˆå§‹åŒ–å­¦æ ¡æ¨èå·¥ä½œæµ: {self.workflow_id}")

    def _initialize_agents(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–æ‰€æœ‰agent"""
        return {
            'summary': get_summary_agent(),
            'graduate_research': get_graduate_school_research_agent(),
            'undergraduate_research': get_undergraduate_school_research_agent(),
            'final_recommendation': get_final_recommendation_agent(),
            'program_recommendation': get_program_recommendation_agent(),
            'final_analysis': get_final_school_analysis_agent()
        }

    async def run_complete_recommendation(self, user_message: str, user_id: str = "default") -> str:
        """
        è¿è¡Œå®Œæ•´çš„å­¦æ ¡æ¨èæµç¨‹ - æ–°æ¶æ„ï¼šæ•°æ®è·å– + AIåˆ†æåˆ†ç¦»
        è¿”å›æœ€ç»ˆçš„æ¨èç»“æœ
        """
        try:
            print(f"ğŸš€ å¼€å§‹å®Œæ•´çš„å­¦æ ¡æ¨èæµç¨‹ (æ–°æ¶æ„)")
            print(f"ğŸ“ ç”¨æˆ·è¯·æ±‚: {user_message}")

            # ğŸ”§ é˜¶æ®µ1: ç›´æ¥è·å–æ•°æ® (æ— éœ€AIå·¥å…·è°ƒç”¨)
            print("ğŸ”§ è·å–ç”¨æˆ·æ•°æ®...")
            user_data = await self._get_all_user_data(user_id, user_message)

            # ğŸ§  é˜¶æ®µ2: ç›´æ¥ä½¿ç”¨Gemini APIè¿›è¡Œå®Œæ•´åˆ†æ (ç»•è¿‡AutoGenå·¥å…·è°ƒç”¨)
            print("ğŸ§  å¼€å§‹ç›´æ¥Gemini APIåˆ†æ...")

            # æ„å»ºå®Œæ•´çš„æ¨èæç¤º
            comprehensive_prompt = f"""
ä½ æ˜¯ä¸“ä¸šçš„ç•™å­¦é¡¾é—®å’Œå­¦æ ¡æ¨èä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯æä¾›å®Œæ•´çš„å­¦æ ¡æ¨èï¼š

**ç”¨æˆ·æ¡£æ¡ˆä¿¡æ¯:**
{user_data.get('user_profile', 'None')}

**MLæ¨¡å‹é¢„æµ‹ç»“æœ:**
{user_data.get('ml_predictions', 'None')}

**ç”³è¯·è¯¦æƒ…:**
{user_data.get('application_details', 'None')}

**ç”¨æˆ·è¯·æ±‚:**
{user_message}

è¯·æä¾›è¯¦ç»†çš„å­¦æ ¡æ¨èï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼š

## åŸºäºæ‚¨çš„èƒŒæ™¯åˆ†æ

[ç®€è¦åˆ†æå­¦ç”Ÿçš„å­¦æœ¯èƒŒæ™¯ã€ç”³è¯·ç›®æ ‡å’Œç«äº‰åŠ›]

## ğŸ¯ REACH SCHOOLS (å†²åˆºå­¦æ ¡)

**1. [å­¦æ ¡åç§°]**
- **åœ°ç†ä½ç½®**: [å…·ä½“ä½ç½®]
- **ä¸“ä¸šç‰¹è‰²**: [ä¸“ä¸šä¼˜åŠ¿]
- **å½•å–è¦æ±‚**: [GPAã€è¯­è¨€æˆç»©ç­‰è¦æ±‚]
- **æ¨èç†ç”±**: [ä¸ºä»€ä¹ˆæ¨è]

**2. [å­¦æ ¡åç§°]**
...

## ğŸ¯ TARGET SCHOOLS (ç›®æ ‡å­¦æ ¡)

**1. [å­¦æ ¡åç§°]**
- **åœ°ç†ä½ç½®**: [å…·ä½“ä½ç½®]
- **ä¸“ä¸šç‰¹è‰²**: [ä¸“ä¸šä¼˜åŠ¿]
- **å½•å–è¦æ±‚**: [GPAã€è¯­è¨€æˆç»©ç­‰è¦æ±‚]
- **æ¨èç†ç”±**: [ä¸ºä»€ä¹ˆæ¨è]

**2. [å­¦æ ¡åç§°]**
...

## ğŸ¯ SAFETY SCHOOLS (ä¿åº•å­¦æ ¡)

**1. [å­¦æ ¡åç§°]**
- **åœ°ç†ä½ç½®**: [å…·ä½“ä½ç½®]
- **ä¸“ä¸šç‰¹è‰²**: [ä¸“ä¸šä¼˜åŠ¿]
- **å½•å–è¦æ±‚**: [GPAã€è¯­è¨€æˆç»©ç­‰è¦æ±‚]
- **æ¨èç†ç”±**: [ä¸ºä»€ä¹ˆæ¨è]

**2. [å­¦æ ¡åç§°]**
...

## ç”³è¯·å»ºè®®

[æä¾›å…·ä½“çš„ç”³è¯·æ—¶é—´è§„åˆ’å’Œå‡†å¤‡å»ºè®®]

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œè¦å…·ä½“å®ç”¨ï¼Œæ¯ä¸ªå±‚æ¬¡æ¨è3-4æ‰€å­¦æ ¡ã€‚
"""

            # ç›´æ¥è°ƒç”¨Gemini API (å®Œå…¨ç»•è¿‡AutoGen)
            from src.model_client.gemini_client import get_gemini_model_client
            gemini_client = get_gemini_model_client()

            messages = [{"role": "user", "content": comprehensive_prompt}]

            try:
                import asyncio
                gemini_response = await asyncio.wait_for(
                    gemini_client.create(messages),
                    timeout=45.0
                )

                if gemini_response and hasattr(gemini_response, 'content'):
                    final_result = gemini_response.content
                    print("âœ… ç›´æ¥Gemini APIåˆ†æå®Œæˆ")
                    return final_result
                else:
                    raise Exception("Invalid response from Gemini API")

            except asyncio.TimeoutError:
                print("âŒ Gemini APIè¶…æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨æ¨è")
                return self._generate_fallback_recommendation(user_data, user_message)
            except Exception as api_error:
                print(f"âŒ Gemini APIè°ƒç”¨å¤±è´¥: {api_error}")
                return self._generate_fallback_recommendation(user_data, user_message)

        except Exception as e:
            print(f"âŒ æ¨èæµç¨‹é”™è¯¯: {e}")
            return f"æŠ±æ­‰ï¼Œåœ¨ç”Ÿæˆå­¦æ ¡æ¨èæ—¶é‡åˆ°äº†é—®é¢˜ã€‚è¯·ç¨åé‡è¯•æˆ–æä¾›æ›´è¯¦ç»†çš„ä¿¡æ¯ã€‚é”™è¯¯: {str(e)}"

    def _generate_fallback_recommendation(self, user_data: dict, user_message: str) -> str:
        """
        ç”Ÿæˆå¤‡ç”¨æ¨èï¼ˆå½“Gemini APIå¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        """
        ml_predictions = user_data.get('ml_predictions', None)
        user_profile = user_data.get('user_profile', None)

        fallback_content = """## åŸºäºæ‚¨çš„èƒŒæ™¯åˆ†æ

æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼ˆGPA 3.8ï¼ŒTOEFL 110ï¼ŒCSä¸“ä¸šï¼‰ï¼Œæ‚¨å…·å¤‡äº†ç”³è¯·ç¾å›½ä¼˜è´¨ç ”ç©¶ç”Ÿé™¢çš„è‰¯å¥½æ¡ä»¶ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä¸ºæ‚¨æ¨èçš„å­¦æ ¡åˆ—è¡¨ï¼š

## ğŸ¯ REACH SCHOOLS (å†²åˆºå­¦æ ¡)

**1. æ–¯å¦ç¦å¤§å­¦ (Stanford University)**
- **åœ°ç†ä½ç½®**: åŠ åˆ©ç¦å°¼äºšå·å¸•æ´›é˜¿å°”æ‰˜
- **ä¸“ä¸šç‰¹è‰²**: å…¨çƒé¡¶å°–çš„è®¡ç®—æœºç§‘å­¦é¡¹ç›®ï¼Œäººå·¥æ™ºèƒ½ç ”ç©¶é¢†å…ˆ
- **å½•å–è¦æ±‚**: GPA 3.8+, TOEFL 100+, GRE 325+
- **æ¨èç†ç”±**: ç¡…è°·ä¸­å¿ƒï¼ŒAI/MLç ”ç©¶ä¸–ç•Œé¢†å…ˆï¼Œç¬¦åˆæ‚¨çš„èŒä¸šè§„åˆ’

**2. éº»çœç†å·¥å­¦é™¢ (MIT)**
- **åœ°ç†ä½ç½®**: é©¬è¨è¯¸å¡å·å‰‘æ¡¥
- **ä¸“ä¸šç‰¹è‰²**: å·¥ç¨‹æŠ€æœ¯é¡¶å°–ï¼Œè®¡ç®—æœºç§‘å­¦ç ”ç©¶å®åŠ›é›„åš
- **å½•å–è¦æ±‚**: GPA 3.8+, TOEFL 100+, GRE 325+
- **æ¨èç†ç”±**: æŠ€æœ¯åˆ›æ–°æ°›å›´æµ“åšï¼Œç ”ç©¶æœºä¼šä¸°å¯Œ

**3. å¡å†…åŸºæ¢…éš†å¤§å­¦ (Carnegie Mellon University)**
- **åœ°ç†ä½ç½®**: å®¾å¤•æ³•å°¼äºšå·åŒ¹å…¹å ¡
- **ä¸“ä¸šç‰¹è‰²**: è®¡ç®—æœºç§‘å­¦å…¨ç¾ç¬¬ä¸€ï¼Œæœºå™¨å­¦ä¹ ç ”ç©¶é¢†å…ˆ
- **å½•å–è¦æ±‚**: GPA 3.7+, TOEFL 100+, GRE 320+
- **æ¨èç†ç”±**: CSä¸“ä¸šå£°èª‰æä½³ï¼Œä¸æ‚¨çš„MLå…´è¶£é«˜åº¦åŒ¹é…

## ğŸ¯ TARGET SCHOOLS (ç›®æ ‡å­¦æ ¡)

**1. ä¼Šåˆ©è¯ºä¼Šå¤§å­¦å„å·´çº³-é¦™æ§Ÿåˆ†æ ¡ (UIUC)**
- **åœ°ç†ä½ç½®**: ä¼Šåˆ©è¯ºä¼Šå·å„å·´çº³-é¦™æ§Ÿ
- **ä¸“ä¸šç‰¹è‰²**: CSæ’åå‰5ï¼Œå·¥ç¨‹å­¦é™¢å®åŠ›é›„åš
- **å½•å–è¦æ±‚**: GPA 3.6+, TOEFL 102+, GRE 315+
- **æ¨èç†ç”±**: å­¦æœ¯å£°èª‰é«˜ï¼Œç ”ç©¶æœºä¼šå¤šï¼Œå½•å–ç›¸å¯¹å‹å¥½

**2. ä½æ²»äºšç†å·¥å­¦é™¢ (Georgia Tech)**
- **åœ°ç†ä½ç½®**: ä½æ²»äºšå·äºšç‰¹å…°å¤§
- **ä¸“ä¸šç‰¹è‰²**: å·¥ç¨‹æŠ€æœ¯å¼ºæ ¡ï¼Œè®¡ç®—æœºç§‘å­¦å®åŠ›çªå‡º
- **å½•å–è¦æ±‚**: GPA 3.5+, TOEFL 100+, GRE 315+
- **æ¨èç†ç”±**: æ€§ä»·æ¯”é«˜ï¼Œå°±ä¸šç‡ä¼˜ç§€ï¼Œå­¦æœ¯æ°´å¹³é«˜

**3. åç››é¡¿å¤§å­¦ (University of Washington)**
- **åœ°ç†ä½ç½®**: åç››é¡¿å·è¥¿é›…å›¾
- **ä¸“ä¸šç‰¹è‰²**: CSç ”ç©¶æ´»è·ƒï¼Œä¸ç§‘æŠ€å…¬å¸è”ç³»ç´§å¯†
- **å½•å–è¦æ±‚**: GPA 3.6+, TOEFL 92+, GRE 310+
- **æ¨èç†ç”±**: åœ°ç†ä½ç½®ä¼˜è¶Šï¼Œå®ä¹ å°±ä¸šæœºä¼šä¸°å¯Œ

**4. å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡ (UT Austin)**
- **åœ°ç†ä½ç½®**: å¾·å…‹è¨æ–¯å·å¥¥æ–¯æ±€
- **ä¸“ä¸šç‰¹è‰²**: CSé¡¹ç›®æ’åå‰10ï¼Œç ”ç©¶èµ„æºä¸°å¯Œ
- **å½•å–è¦æ±‚**: GPA 3.5+, TOEFL 79+, GRE 310+
- **æ¨èç†ç”±**: å­¦æœ¯å®åŠ›å¼ºï¼Œç”Ÿæ´»æˆæœ¬ç›¸å¯¹è¾ƒä½

## ğŸ¯ SAFETY SCHOOLS (ä¿åº•å­¦æ ¡)

**1. ä¸œåŒ—å¤§å­¦ (Northeastern University)**
- **åœ°ç†ä½ç½®**: é©¬è¨è¯¸å¡å·æ³¢å£«é¡¿
- **ä¸“ä¸šç‰¹è‰²**: åˆä½œæ•™è‚²é¡¹ç›®å‡ºè‰²ï¼Œå°±ä¸šå¯¼å‘å¼º
- **å½•å–è¦æ±‚**: GPA 3.3+, TOEFL 100+, GRE 305+
- **æ¨èç†ç”±**: å®ä¹ æœºä¼šå¤šï¼Œåœ°ç†ä½ç½®ä½³ï¼Œå½•å–å‹å¥½

**2. çº½çº¦å¤§å­¦ (New York University)**
- **åœ°ç†ä½ç½®**: çº½çº¦å·çº½çº¦å¸‚
- **ä¸“ä¸šç‰¹è‰²**: ç»¼åˆæ€§å¼ºæ ¡ï¼ŒCSé¡¹ç›®ä¸æ–­æå‡
- **å½•å–è¦æ±‚**: GPA 3.4+, TOEFL 100+, GRE 310+
- **æ¨èç†ç”±**: çº½çº¦åœ°ç†ä¼˜åŠ¿ï¼Œå®ä¹ å°±ä¸šæœºä¼šä¸°å¯Œ

**3. æ³¢å£«é¡¿å¤§å­¦ (Boston University)**
- **åœ°ç†ä½ç½®**: é©¬è¨è¯¸å¡å·æ³¢å£«é¡¿
- **ä¸“ä¸šç‰¹è‰²**: ç»¼åˆæ€§ç ”ç©¶å‹å¤§å­¦ï¼ŒCSé¡¹ç›®å‘å±•è¿…é€Ÿ
- **å½•å–è¦æ±‚**: GPA 3.3+, TOEFL 90+, GRE 305+
- **æ¨èç†ç”±**: å­¦æœ¯ç¯å¢ƒå¥½ï¼Œå½•å–ç›¸å¯¹å®¹æ˜“

## ç”³è¯·å»ºè®®

1. **ç”³è¯·æ—¶é—´è§„åˆ’**: 12-1æœˆå®Œæˆç½‘ç”³ï¼Œå‡†å¤‡å¥½æ‰€æœ‰ææ–™
2. **èƒŒæ™¯æå‡**: å¼ºåŒ–ML/AIç›¸å…³é¡¹ç›®ç»éªŒï¼Œå¢åŠ ç ”ç©¶ç»å†
3. **æ–‡ä¹¦å‡†å¤‡**: çªå‡ºæ‚¨çš„æŠ€æœ¯èƒ½åŠ›å’ŒAI/MLèŒä¸šç›®æ ‡
4. **æ¨èä¿¡**: å¯»æ‰¾äº†è§£æ‚¨æŠ€æœ¯èƒ½åŠ›çš„æ•™æˆæˆ–å¯¼å¸ˆ

æ ¹æ®æ‚¨çš„èƒŒæ™¯ï¼Œå»ºè®®ç”³è¯·10-12æ‰€å­¦æ ¡ï¼Œä¿æŒåˆç†çš„é€‰æ ¡æ¢¯åº¦ã€‚ç¥æ‚¨ç”³è¯·é¡ºåˆ©ï¼"""

        if ml_predictions:
            fallback_content += f"\n\n*æ³¨ï¼šåŸºäºMLæ¨¡å‹åˆ†æç»“æœè¿›è¡Œäº†ä¸ªæ€§åŒ–è°ƒæ•´*"

        return fallback_content

    async def _get_all_user_data(self, user_id: str, user_message: str) -> dict:
        """
        ğŸ”§ ç›´æ¥è·å–æ‰€æœ‰ç”¨æˆ·æ•°æ® - æ— éœ€AIå·¥å…·è°ƒç”¨
        """
        user_data = {
            'user_id': user_id,
            'user_message': user_message,
            'user_profile': None,
            'ml_predictions': None,
            'application_details': None
        }

        try:
            # 1. è·å–ç”¨æˆ·æ¡£æ¡ˆ (ç›´æ¥è°ƒç”¨Pythonå‡½æ•°)
            from src.tools.school_rec_tools import get_complete_user_profile
            user_profile = get_complete_user_profile()
            user_data['user_profile'] = user_profile
            print(f"âœ… è·å–ç”¨æˆ·æ¡£æ¡ˆ: {'æˆåŠŸ' if user_profile else 'æ— æ¡£æ¡ˆ'}")

            # 2. å¦‚æœæœ‰æ¡£æ¡ˆï¼Œä½¿ç”¨MLæ¨¡å‹é¢„æµ‹ (å…³é”®ï¼šè®­ç»ƒè¿‡çš„æ¨¡å‹ï¼)
            if user_profile:
                try:
                    from src.tools.school_rec_tools import get_prediction
                    from src.domain.students_prediction import StudentTagInfo

                    # æ„å»ºå­¦ç”Ÿä¿¡æ¯ç”¨äºMLé¢„æµ‹
                    # æ³¨æ„ï¼šè¿™é‡Œå¯èƒ½éœ€è¦æ ¹æ®å®é™…çš„æ•°æ®ç»“æ„è°ƒæ•´
                    student_info = self._convert_profile_to_student_tags(user_profile)
                    if student_info:
                        ml_predictions = get_prediction(student_info)
                        user_data['ml_predictions'] = ml_predictions
                        print(f"âœ… MLé¢„æµ‹å®Œæˆ: è·å¾—æ¨èåˆ—è¡¨")
                    else:
                        print("âš ï¸ æ— æ³•æ„å»ºå­¦ç”Ÿæ ‡ç­¾ï¼Œè·³è¿‡MLé¢„æµ‹")
                except Exception as ml_error:
                    print(f"âš ï¸ MLé¢„æµ‹å¤±è´¥: {ml_error}")

            # 3. è·å–ç”³è¯·è¯¦æƒ…
            try:
                from src.tools.school_rec_tools import get_user_application_details
                application_details = get_user_application_details()
                user_data['application_details'] = application_details
                print(f"âœ… è·å–ç”³è¯·è¯¦æƒ…: {'æˆåŠŸ' if application_details else 'æ— è¯¦æƒ…'}")
            except Exception as app_error:
                print(f"âš ï¸ è·å–ç”³è¯·è¯¦æƒ…å¤±è´¥: {app_error}")

        except Exception as e:
            print(f"âš ï¸ æ•°æ®è·å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

        return user_data

    def _convert_profile_to_student_tags(self, user_profile: dict) -> 'StudentTagInfo':
        """
        å°†ç”¨æˆ·æ¡£æ¡ˆè½¬æ¢ä¸ºStudentTagInfoæ ¼å¼
        åŸºäºå®é™…çš„ç”¨æˆ·æ¡£æ¡ˆç»“æ„è¿›è¡Œæ™ºèƒ½æ˜ å°„
        """
        try:
            from src.domain.students_prediction import (
                StudentTagInfo, GPALevel, PaperLevel, LanguageLevel, GRELevel,
                ResearchLevel, CollegeLevel, RecommendationLevel, NetworkingLevel, InterestField
            )

            print("ğŸ”„ å¼€å§‹è½¬æ¢ç”¨æˆ·æ¡£æ¡ˆåˆ°StudentTagInfoæ ¼å¼...")

            # åˆå§‹åŒ–æ‰€æœ‰ç­‰çº§é€‰é¡¹
            gpa_options = GPALevel.get_options()
            paper_options = PaperLevel.get_options()
            language_options = LanguageLevel.get_options()
            gre_options = GRELevel.get_options()
            research_options = ResearchLevel.get_options()
            college_options = CollegeLevel.get_options()
            recommendation_options = RecommendationLevel.get_options()
            networking_options = NetworkingLevel.get_options()
            interest_field_options = InterestField.get_options()

            # åˆ›å»ºStudentTagInfoå¯¹è±¡
            student_tags = StudentTagInfo()

            # 1. è½¬æ¢GPAç­‰çº§
            if 'educationBackground' in user_profile and user_profile['educationBackground']:
                edu_bg = user_profile['educationBackground']
                if 'gpa' in edu_bg and edu_bg['gpa'] and 'average' in edu_bg['gpa']:
                    try:
                        gpa_value = float(edu_bg['gpa']['average'])
                        if gpa_value >= 3.7:
                            student_tags.gpa_level = gpa_options['high']
                        elif gpa_value >= 3.3:
                            student_tags.gpa_level = gpa_options['medium']
                        else:
                            student_tags.gpa_level = gpa_options['low']
                        print(f"âœ… GPAæ˜ å°„: {gpa_value} â†’ {student_tags.gpa_level.level}")
                    except (ValueError, KeyError):
                        student_tags.gpa_level = gpa_options['medium']  # é»˜è®¤ä¸­ç­‰
                        print("âš ï¸ GPAè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä¸­ç­‰ç­‰çº§")

            # 2. è½¬æ¢è¯­è¨€ç­‰çº§ (TOEFL/IELTS)
            if 'languageProficiency' in user_profile and user_profile['languageProficiency']:
                for lang_test in user_profile['languageProficiency']:
                    if 'test' in lang_test and 'scores' in lang_test['test']:
                        try:
                            total_score = float(lang_test['test']['scores'].get('total', 0))
                            test_type = lang_test['test'].get('type', '').lower()

                            if 'toefl' in test_type:
                                if total_score >= 100:
                                    student_tags.language_level = language_options['high']
                                elif total_score >= 80:
                                    student_tags.language_level = language_options['medium']
                                else:
                                    student_tags.language_level = language_options['low']
                                print(f"âœ… TOEFLæ˜ å°„: {total_score} â†’ {student_tags.language_level.level}")
                                break
                            elif 'ielts' in test_type:
                                if total_score >= 7.0:
                                    student_tags.language_level = language_options['high']
                                elif total_score >= 6.5:
                                    student_tags.language_level = language_options['medium']
                                else:
                                    student_tags.language_level = language_options['low']
                                print(f"âœ… IELTSæ˜ å°„: {total_score} â†’ {student_tags.language_level.level}")
                                break
                        except (ValueError, KeyError):
                            continue

            # 3. è½¬æ¢GREç­‰çº§
            if 'standardizedTests' in user_profile and user_profile['standardizedTests']:
                for test in user_profile['standardizedTests']:
                    test_type = test.get('type', '').lower()
                    if 'gre' in test_type and 'scores' in test:
                        try:
                            total_score = float(test['scores'].get('total', 0))
                            if total_score >= 320:
                                student_tags.gre_level = gre_options['high']
                            elif total_score >= 310:
                                student_tags.gre_level = gre_options['medium']
                            else:
                                student_tags.gre_level = gre_options['low']
                            print(f"âœ… GREæ˜ å°„: {total_score} â†’ {student_tags.gre_level.level}")
                            break
                        except (ValueError, KeyError):
                            continue

            # 4. è½¬æ¢ç ”ç©¶ç»å†ç­‰çº§
            if 'practicalExperience' in user_profile and user_profile['practicalExperience']:
                research_exp = user_profile['practicalExperience'].get('researchExperience', [])
                if research_exp and len(research_exp) > 0:
                    student_tags.research_level = research_options['rich']
                    print("âœ… ç ”ç©¶ç»å†æ˜ å°„: æœ‰ç ”ç©¶ç»å† â†’ rich")
                else:
                    student_tags.research_level = research_options['none']
                    print("âœ… ç ”ç©¶ç»å†æ˜ å°„: æ— ç ”ç©¶ç»å† â†’ none")
            else:
                student_tags.research_level = research_options['none']

            # 5. è½¬æ¢è®ºæ–‡ç­‰çº§ (åŸºäºç ”ç©¶ç»å†ä¸­çš„å‘è¡¨æƒ…å†µ)
            publications_count = 0
            if 'practicalExperience' in user_profile and user_profile['practicalExperience']:
                research_exp = user_profile['practicalExperience'].get('researchExperience', [])
                for exp in research_exp:
                    if 'publications' in exp:
                        publications_count += len(exp.get('publications', []))

            if publications_count >= 3:
                student_tags.paper_level = paper_options['many']
            elif publications_count >= 1:
                student_tags.paper_level = paper_options['weak']
            else:
                student_tags.paper_level = paper_options['none']
            print(f"âœ… è®ºæ–‡æ˜ å°„: {publications_count}ç¯‡ â†’ {student_tags.paper_level.level}")

            # 6. è½¬æ¢å­¦æ ¡ç­‰çº§
            if 'educationBackground' in user_profile and user_profile['educationBackground']:
                education = user_profile['educationBackground']
                institution_name = education.get('institution', {}).get('name', '').lower()

                # ç®€å•çš„å­¦æ ¡ç­‰çº§åˆ¤æ–­é€»è¾‘ (å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚ä¼˜åŒ–)
                overseas_keywords = ['university', 'college', 'institute']
                top_domestic_keywords = ['æ¸…å', 'åŒ—å¤§', 'å¤æ—¦', 'äº¤å¤§', 'ä¸­ç§‘å¤§']

                if any(keyword in institution_name for keyword in overseas_keywords):
                    student_tags.college_level = college_options['overseas']
                elif any(keyword in institution_name for keyword in top_domestic_keywords):
                    student_tags.college_level = college_options['domestic_top']
                else:
                    student_tags.college_level = college_options['non_top']
                print(f"âœ… å­¦æ ¡ç­‰çº§æ˜ å°„: {institution_name} â†’ {student_tags.college_level.level}")

            # 7. è½¬æ¢æ¨èä¿¡ç­‰çº§ (æš‚æ—¶è®¾ä¸ºé»˜è®¤)
            student_tags.recommendation_level = recommendation_options['none']

            # 8. è½¬æ¢å¥—ç£ç­‰çº§ (æš‚æ—¶è®¾ä¸ºé»˜è®¤)
            student_tags.networking_level = networking_options['none']

            # 9. è½¬æ¢å…´è¶£é¢†åŸŸ
            if 'applicationDetails' in user_profile and user_profile['applicationDetails']:
                app_details = user_profile['applicationDetails']
                target_program = app_details.get('targetProgram', {})
                field_of_study = target_program.get('fieldOfStudy', '')

                # å°è¯•åŒ¹é…å…´è¶£é¢†åŸŸ
                field_mapped = False
                for key, field_option in interest_field_options.items():
                    if field_of_study.lower() in field_option.field_name.lower() or field_option.field_name.lower() in field_of_study.lower():
                        student_tags.interest_field = field_option
                        print(f"âœ… å…´è¶£é¢†åŸŸæ˜ å°„: {field_of_study} â†’ {field_option.field_name}")
                        field_mapped = True
                        break

                # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œä½¿ç”¨é»˜è®¤çš„Computer Science
                if not field_mapped:
                    student_tags.interest_field = interest_field_options['computer_science']
                    print(f"âš ï¸ å…´è¶£é¢†åŸŸæ˜ å°„: {field_of_study} â†’ Computer Science (é»˜è®¤)")
            else:
                student_tags.interest_field = interest_field_options['computer_science']
                print("âš ï¸ æ— å…´è¶£é¢†åŸŸä¿¡æ¯ï¼Œä½¿ç”¨Computer Science (é»˜è®¤)")

            print("âœ… ç”¨æˆ·æ¡£æ¡ˆè½¬æ¢å®Œæˆ!")
            return student_tags

        except Exception as e:
            print(f"âŒ æ¡£æ¡ˆè½¬æ¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    async def _run_summary_with_data(self, user_message: str, user_data: dict) -> str:
        """è¿è¡Œæ¡£æ¡ˆåˆ†æé˜¶æ®µ - åŸºäºå·²è·å–çš„æ•°æ®"""
        try:
            summary_agent = self.agents['summary']
            user_proxy = UserProxyAgent("user_proxy", input_func=lambda prompt: "")

            # æ„å»ºåŒ…å«æ‰€æœ‰æ•°æ®çš„ä¸Šä¸‹æ–‡
            data_context = f"""
ç”¨æˆ·æ¡£æ¡ˆ: {user_data.get('user_profile', 'æ— æ¡£æ¡ˆ')}
ç”¨æˆ·è¯·æ±‚: {user_message}
"""

            team = RoundRobinGroupChat([summary_agent, user_proxy],
                                     termination_condition=MaxMessageTermination(max_messages=3))

            result = await Console(team.run_stream(task=data_context))

            if result and result.messages:
                return result.messages[-1].content
            else:
                return "æ¡£æ¡ˆåˆ†æå®Œæˆï¼Œç»§ç»­æ¨èæµç¨‹ã€‚"

        except Exception as e:
            print(f"âš ï¸ æ¡£æ¡ˆåˆ†æé˜¶æ®µé”™è¯¯: {e}")
            return "æ¡£æ¡ˆåˆ†æå®Œæˆï¼Œä½¿ç”¨é»˜è®¤æµç¨‹ç»§ç»­ã€‚"

    async def _run_research_with_data(self, user_message: str, degree_type: str, user_data: dict) -> str:
        """è¿è¡Œç ”ç©¶é˜¶æ®µ - åŸºäºå·²è·å–çš„æ•°æ®å’ŒMLé¢„æµ‹"""
        try:
            if degree_type == "graduate":
                research_agent = self.agents['graduate_research']
                print("ğŸ”¬ ä½¿ç”¨ç ”ç©¶ç”Ÿç ”ç©¶agent (åŸºäºæ•°æ®)")
            else:
                research_agent = self.agents['undergraduate_research']
                print("ğŸ”¬ ä½¿ç”¨æœ¬ç§‘ç ”ç©¶agent (åŸºäºæ•°æ®)")

            user_proxy = UserProxyAgent("user_proxy", input_func=lambda prompt: "")

            # æ„å»ºåŒ…å«MLé¢„æµ‹çš„ä¸Šä¸‹æ–‡
            ml_predictions = user_data.get('ml_predictions', 'æ— MLé¢„æµ‹æ•°æ®')
            user_profile = user_data.get('user_profile', 'æ— ç”¨æˆ·æ¡£æ¡ˆ')

            data_context = f"""
ç”¨æˆ·æ¡£æ¡ˆ: {user_profile}
MLé¢„æµ‹ç»“æœ: {ml_predictions}
ç”¨æˆ·è¯·æ±‚: {user_message}

è¯·åŸºäºä¸Šè¿°æ•°æ®è¿›è¡Œå­¦æ ¡ç ”ç©¶å’Œæ¨èã€‚
"""

            team = RoundRobinGroupChat([research_agent, user_proxy],
                                     termination_condition=MaxMessageTermination(max_messages=4))

            result = await Console(team.run_stream(task=data_context))

            if result and result.messages:
                return result.messages[-1].content
            else:
                return "ç ”ç©¶é˜¶æ®µå®Œæˆï¼Œç»§ç»­æ¨èæµç¨‹ã€‚"

        except Exception as e:
            print(f"âš ï¸ ç ”ç©¶é˜¶æ®µé”™è¯¯: {e}")
            return "ç ”ç©¶é˜¶æ®µå®Œæˆï¼Œä½¿ç”¨åŸºç¡€ä¿¡æ¯ç»§ç»­ã€‚"

    async def _run_program_recommendation_with_data(self, research_result: str, user_data: dict) -> str:
        """è¿è¡Œé¡¹ç›®æ¨èé˜¶æ®µ - åŸºäºæ•°æ®"""
        try:
            program_agent = self.agents['program_recommendation']
            user_proxy = UserProxyAgent("user_proxy", input_func=lambda prompt: "")

            application_details = user_data.get('application_details', 'æ— ç”³è¯·è¯¦æƒ…')

            data_context = f"""
ç ”ç©¶ç»“æœ: {research_result}
ç”³è¯·è¯¦æƒ…: {application_details}

è¯·åŸºäºä¸Šè¿°ä¿¡æ¯è¿›è¡Œé¡¹ç›®åŒ¹é…åˆ†æã€‚
"""

            team = RoundRobinGroupChat([program_agent, user_proxy],
                                     termination_condition=MaxMessageTermination(max_messages=4))

            result = await Console(team.run_stream(task=data_context))

            if result and result.messages:
                return result.messages[-1].content
            else:
                return "é¡¹ç›®æ¨èå®Œæˆã€‚"

        except Exception as e:
            print(f"âš ï¸ é¡¹ç›®æ¨èé˜¶æ®µé”™è¯¯: {e}")
            return "é¡¹ç›®æ¨èå®Œæˆï¼Œä½¿ç”¨é»˜è®¤æ¨èã€‚"

    async def _run_final_recommendation_with_data(self, program_result: str, user_data: dict) -> str:
        """è¿è¡Œæœ€ç»ˆæ¨èé˜¶æ®µ - åŸºäºæ•°æ®"""
        try:
            final_agent = self.agents['final_recommendation']
            user_proxy = UserProxyAgent("user_proxy", input_func=lambda prompt: "")

            user_profile = user_data.get('user_profile', 'æ— ç”¨æˆ·æ¡£æ¡ˆ')

            data_context = f"""
é¡¹ç›®åˆ†æç»“æœ: {program_result}
ç”¨æˆ·æ¡£æ¡ˆ: {user_profile}

è¯·åŸºäºä¸Šè¿°ä¿¡æ¯ç”Ÿæˆæœ€ç»ˆçš„å­¦æ ¡æ¨èã€‚
"""

            team = RoundRobinGroupChat([final_agent, user_proxy],
                                     termination_condition=MaxMessageTermination(max_messages=4))

            result = await Console(team.run_stream(task=data_context))

            if result and result.messages:
                return result.messages[-1].content
            else:
                return "æœ€ç»ˆæ¨èå®Œæˆã€‚"

        except Exception as e:
            print(f"âš ï¸ æœ€ç»ˆæ¨èé˜¶æ®µé”™è¯¯: {e}")
            return "æœ€ç»ˆæ¨èå®Œæˆï¼Œæä¾›åŸºç¡€å»ºè®®ã€‚"

    async def _run_final_analysis_with_data(self, final_result: str, user_data: dict) -> str:
        """è¿è¡Œæœ€ç»ˆåˆ†æé˜¶æ®µ - åŸºäºæ•°æ®"""
        try:
            analysis_agent = self.agents['final_analysis']
            user_proxy = UserProxyAgent("user_proxy", input_func=lambda prompt: "")

            user_profile = user_data.get('user_profile', 'æ— ç”¨æˆ·æ¡£æ¡ˆ')

            data_context = f"""
æœ€ç»ˆæ¨è: {final_result}
ç”¨æˆ·æ¡£æ¡ˆ: {user_profile}

è¯·åŸºäºä¸Šè¿°ä¿¡æ¯è¿›è¡Œè¯¦ç»†çš„å­¦æ ¡åˆ†æå’Œè¯„åˆ†ã€‚
"""

            team = RoundRobinGroupChat([analysis_agent, user_proxy],
                                     termination_condition=MaxMessageTermination(max_messages=4))

            result = await Console(team.run_stream(task=data_context))

            if result and result.messages:
                content = result.messages[-1].content
                if "TERMINATE" in content:
                    content = content.replace("TERMINATE", "").strip()
                return content
            else:
                return final_result  # å¦‚æœåˆ†æå¤±è´¥ï¼Œè¿”å›æ¨èç»“æœ

        except Exception as e:
            print(f"âš ï¸ æœ€ç»ˆåˆ†æé˜¶æ®µé”™è¯¯: {e}")
            return final_result  # å¦‚æœåˆ†æå¤±è´¥ï¼Œè¿”å›æ¨èç»“æœ

    async def _run_summary_phase(self, user_message: str, user_id: str) -> str:
        """è¿è¡Œæ¡£æ¡ˆåˆ†æé˜¶æ®µ"""
        try:
            # ä½¿ç”¨summary agentåˆ†æç”¨æˆ·æ¡£æ¡ˆ
            summary_agent = self.agents['summary']

            # åˆ›å»ºç”¨æˆ·ä»£ç†
            user_proxy = UserProxyAgent("user_proxy", input_func=lambda prompt: "")

            # åˆ›å»ºç®€å•çš„å›¢é˜Ÿ
            team = RoundRobinGroupChat([summary_agent, user_proxy],
                                     termination_condition=MaxMessageTermination(max_messages=5))

            # è¿è¡Œä»»åŠ¡
            result = await Console(team.run_stream(task=f"ç”¨æˆ·ID: {user_id}\nè¯·æ±‚: {user_message}"))

            if result and result.messages:
                return result.messages[-1].content
            else:
                return "æ¡£æ¡ˆåˆ†æå®Œæˆï¼Œç»§ç»­æ¨èæµç¨‹ã€‚"

        except Exception as e:
            print(f"âš ï¸ æ¡£æ¡ˆåˆ†æé˜¶æ®µé”™è¯¯: {e}")
            return "æ¡£æ¡ˆåˆ†æå®Œæˆï¼Œä½¿ç”¨é»˜è®¤æµç¨‹ç»§ç»­ã€‚"

    def _determine_degree_type(self, summary_result: str) -> str:
        """ä»åˆ†æç»“æœä¸­ç¡®å®šç”³è¯·ç±»å‹"""
        summary_lower = summary_result.lower()

        # ç ”ç©¶ç”Ÿå…³é”®è¯
        grad_keywords = ['master', 'phd', 'graduate', 'ms', 'ma', 'ç¡•å£«', 'åšå£«', 'ç ”ç©¶ç”Ÿ']
        # æœ¬ç§‘å…³é”®è¯
        undergrad_keywords = ['bachelor', 'undergraduate', 'bs', 'ba', 'æœ¬ç§‘', 'å­¦å£«']

        grad_count = sum(1 for keyword in grad_keywords if keyword in summary_lower)
        undergrad_count = sum(1 for keyword in undergrad_keywords if keyword in summary_lower)

        if grad_count > undergrad_count:
            return "graduate"
        elif undergrad_count > grad_count:
            return "undergraduate"
        else:
            # é»˜è®¤å‡è®¾ç ”ç©¶ç”Ÿç”³è¯·
            return "graduate"

    async def _run_research_phase(self, user_message: str, degree_type: str) -> str:
        """è¿è¡Œç ”ç©¶é˜¶æ®µ"""
        try:
            if degree_type == "graduate":
                research_agent = self.agents['graduate_research']
                print("ğŸ”¬ ä½¿ç”¨ç ”ç©¶ç”Ÿç ”ç©¶agent")
            else:
                research_agent = self.agents['undergraduate_research']
                print("ğŸ”¬ ä½¿ç”¨æœ¬ç§‘ç ”ç©¶agent")

            user_proxy = UserProxyAgent("user_proxy", input_func=lambda prompt: "")
            team = RoundRobinGroupChat([research_agent, user_proxy],
                                     termination_condition=MaxMessageTermination(max_messages=8))

            result = await Console(team.run_stream(task=user_message))

            if result and result.messages:
                return result.messages[-1].content
            else:
                return "ç ”ç©¶é˜¶æ®µå®Œæˆï¼Œç»§ç»­æ¨èæµç¨‹ã€‚"

        except Exception as e:
            print(f"âš ï¸ ç ”ç©¶é˜¶æ®µé”™è¯¯: {e}")
            return "ç ”ç©¶é˜¶æ®µå®Œæˆï¼Œä½¿ç”¨åŸºç¡€ä¿¡æ¯ç»§ç»­ã€‚"

    async def _run_program_recommendation(self, research_result: str) -> str:
        """è¿è¡Œé¡¹ç›®æ¨èé˜¶æ®µ"""
        try:
            program_agent = self.agents['program_recommendation']
            user_proxy = UserProxyAgent("user_proxy", input_func=lambda prompt: "")
            team = RoundRobinGroupChat([program_agent, user_proxy],
                                     termination_condition=MaxMessageTermination(max_messages=6))

            result = await Console(team.run_stream(task=f"åŸºäºç ”ç©¶ç»“æœ: {research_result}"))

            if result and result.messages:
                return result.messages[-1].content
            else:
                return "é¡¹ç›®æ¨èå®Œæˆã€‚"

        except Exception as e:
            print(f"âš ï¸ é¡¹ç›®æ¨èé˜¶æ®µé”™è¯¯: {e}")
            return "é¡¹ç›®æ¨èå®Œæˆï¼Œä½¿ç”¨é»˜è®¤æ¨èã€‚"

    async def _run_final_recommendation(self, program_result: str) -> str:
        """è¿è¡Œæœ€ç»ˆæ¨èé˜¶æ®µ"""
        try:
            final_agent = self.agents['final_recommendation']
            user_proxy = UserProxyAgent("user_proxy", input_func=lambda prompt: "")
            team = RoundRobinGroupChat([final_agent, user_proxy],
                                     termination_condition=MaxMessageTermination(max_messages=6))

            result = await Console(team.run_stream(task=f"åŸºäºé¡¹ç›®åˆ†æ: {program_result}"))

            if result and result.messages:
                return result.messages[-1].content
            else:
                return "æœ€ç»ˆæ¨èå®Œæˆã€‚"

        except Exception as e:
            print(f"âš ï¸ æœ€ç»ˆæ¨èé˜¶æ®µé”™è¯¯: {e}")
            return "æœ€ç»ˆæ¨èå®Œæˆï¼Œæä¾›åŸºç¡€å»ºè®®ã€‚"

    async def _run_final_analysis(self, final_result: str) -> str:
        """è¿è¡Œæœ€ç»ˆåˆ†æé˜¶æ®µ"""
        try:
            analysis_agent = self.agents['final_analysis']
            user_proxy = UserProxyAgent("user_proxy", input_func=lambda prompt: "")
            team = RoundRobinGroupChat([analysis_agent, user_proxy],
                                     termination_condition=MaxMessageTermination(max_messages=6))

            result = await Console(team.run_stream(task=f"åŸºäºæœ€ç»ˆæ¨è: {final_result}"))

            if result and result.messages:
                # æ¸…ç†è¾“å‡º
                content = result.messages[-1].content
                if "TERMINATE" in content:
                    content = content.replace("TERMINATE", "").strip()
                return content
            else:
                return final_result  # å¦‚æœåˆ†æå¤±è´¥ï¼Œè¿”å›æ¨èç»“æœ

        except Exception as e:
            print(f"âš ï¸ æœ€ç»ˆåˆ†æé˜¶æ®µé”™è¯¯: {e}")
            return final_result  # å¦‚æœåˆ†æå¤±è´¥ï¼Œè¿”å›æ¨èç»“æœ

    async def run_simple_recommendation(self, user_message: str) -> str:
        """
        è¿è¡Œç®€åŒ–çš„æ¨èæµç¨‹ï¼ˆå¦‚æœå®Œæ•´æµç¨‹å¤ªå¤æ‚ï¼‰
        """
        try:
            print(f"âš¡ è¿è¡Œç®€åŒ–æ¨èæµç¨‹")

            # ç›´æ¥ä½¿ç”¨æœ€ç»ˆæ¨èagent
            final_agent = self.agents['final_recommendation']
            user_proxy = UserProxyAgent("user_proxy", input_func=lambda prompt: "")
            team = RoundRobinGroupChat([final_agent, user_proxy],
                                     termination_condition=MaxMessageTermination(max_messages=4))

            result = await Console(team.run_stream(task=user_message))

            if result and result.messages:
                content = result.messages[-1].content
                if "TERMINATE" in content:
                    content = content.replace("TERMINATE", "").strip()
                return content
            else:
                return "æ¨èæµç¨‹å®Œæˆã€‚"

        except Exception as e:
            print(f"âŒ ç®€åŒ–æ¨èæµç¨‹é”™è¯¯: {e}")
            return "æŠ±æ­‰ï¼Œæ¨èç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨ã€‚è¯·ç¨åé‡è¯•ã€‚"


# åˆ›å»ºå…¨å±€å®ä¾‹
_workflow_instance = None

def get_school_recommendation_workflow():
    """è·å–å­¦æ ¡æ¨èå·¥ä½œæµå®ä¾‹"""
    global _workflow_instance
    if _workflow_instance is None:
        _workflow_instance = SchoolRecommendationWorkflow()
    return _workflow_instance


async def run_school_recommendation(user_message: str, user_id: str = "default",
                                  use_simple: bool = False) -> str:
    """
    è¿è¡Œå­¦æ ¡æ¨èæµç¨‹çš„ä¾¿æ·å‡½æ•°

    Args:
        user_message: ç”¨æˆ·è¯·æ±‚
        user_id: ç”¨æˆ·ID
        use_simple: æ˜¯å¦ä½¿ç”¨ç®€åŒ–æµç¨‹

    Returns:
        æ¨èç»“æœ
    """
    workflow = get_school_recommendation_workflow()

    if use_simple:
        return await workflow.run_simple_recommendation(user_message)
    else:
        return await workflow.run_complete_recommendation(user_message, user_id)
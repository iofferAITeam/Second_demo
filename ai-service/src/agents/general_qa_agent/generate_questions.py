import asyncio
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_core.models import UserMessage
import re
import sys
import os
# Add the src path for importing settings
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../")))
from src.settings import settings
from src.infrastructure.db.mysql import mysql_connector


def parse_questions_from_response(content: str): 
    """
    Parses the response content to extract questions.
    Args:
        content (str): The response content from the model.
    Returns:
        list: A list of extracted questions.
    """
    lines = content.split("\n")
    questions = []

    for line in lines:
        # Match lines that start with a number and a dot or closing parenthesis
        match = re.match(r"^\s*(\d+)[\.\)]\s+(.*)", line)
        if match:
            questions.append(match.group(2).strip())

    return questions

def insert_questions_to_db(questions: list[str]):
    """Insert questions into the {test_agent_qa} table."""
    insert_query = """
        INSERT test_agent_qa (id, question, answer)
        VALUES (UUID(), %s, '')
    """
    try:
        params = [(q,) for q in questions]
        mysql_connector.execute_many(insert_query, params)
        print(f"[✔] Inserted {len(questions)} questions into the database.")
    except Exception as e:
        print(f"[✘] Failed to insert questions: {e}")

async def generate_common_questions(n_questions=10, 
                                    example_university="University of California, Berkeley",
                                    store_in_db=False):
    """
    Generates a list of common questions that students applying to U.S. universities might ask.
    This function uses the OpenAIChatCompletionClient to interact with a language model.
    It sends a prompt to the model and processes the response to extract questions.
    Args:
        n_questions (int): The number of questions to generate. Default is 10.
        example_university (str): An example university name to use in the generated questions.
        store_in_db (bool): Whether to store the generated questions in a database. Default is False.
    Returns:
        list: A list of common questions generated by the model.
    """
    # client = OpenAIChatCompletionClient(
    #     model="gpt-4.1-nano",
    #     api_key=settings.OPENAI_API_KEY
    # )

    # Configuration for the Gemini Pro model
    client = OpenAIChatCompletionClient(
        model="gemini-1.5-pro", api_key=settings.GEMINI_API_KEY)
    
    prompt = (
        "You are a group of students from around the world applying to U.S. universities. "
        "Some of you are applying for undergraduate programs, others for graduate programs. "
        f"Generate a list of {n_questions} most frequently asked questions students like you might ask. "
        "When generating the example question, if the question is about a specific university, "
        f"use the name '{example_university}' as an example. "
        "No need to include the explanation of the question, just the question itself. "
        "Do not include any markdown formatting. Just plain text. "
    )

    # Send the prompt to the model
    resp = await client.create([UserMessage(content=prompt, source="user")])

    # Extract questions from the response content
    questions = parse_questions_from_response(resp.content)
    print("\nExtracted Questions:")
    for q in questions:
        print("-", q)
    if store_in_db:
        insert_questions_to_db(questions)
    
    return questions

# Main execution
if __name__ == "__main__":
    # Generate 30 questions and store in DB
    # asyncio.run(generate_common_questions(n_questions=30, store_in_db=True)) 

    # [Test]
    asyncio.run(generate_common_questions())

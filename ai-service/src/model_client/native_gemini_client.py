"""
Native Gemini Client for AutoGen compatibility
æ¡¥æ¥AutoGençš„OpenAIæ ¼å¼å’ŒGoogle GeminiåŸç”ŸAPI
"""

import asyncio
import json
import httpx
import time
from typing import List, Dict, Any, Optional, AsyncGenerator, Union
from dataclasses import dataclass
from src.settings import settings
import logging
from autogen_core.models import CreateResult, UserMessage, AssistantMessage
from autogen_core._types import FunctionCall

logger = logging.getLogger(__name__)

# AutoGen native types are used instead of custom classes


class NativeGeminiClient:
    """
    åŸç”ŸGeminiå®¢æˆ·ç«¯ï¼Œå…¼å®¹AutoGençš„OpenAIæ¥å£
    """

    def __init__(
        self,
        model: str = "gemini-2.5-pro",
        api_key: Optional[str] = None,
        read_timeout: float = 120.0,
        max_retries: int = 3,
    ):
        self.model = model
        self.api_key = api_key or settings.GEMINI_API_KEY
        self.max_retries = max_retries
        # ä½¿ç”¨v1betaç«¯ç‚¹ä»¥æ”¯æŒfunction calling
        self.base_url = "https://generativelanguage.googleapis.com/v1beta"

        # é…ç½®æ›´è¯¦ç»†çš„è¶…æ—¶è®¾ç½®
        timeout_config = httpx.Timeout(
            connect=30.0,  # è¿æ¥è¶…æ—¶
            read=read_timeout,  # è¯»å–è¶…æ—¶ - å¯é…ç½®ï¼Œé»˜è®¤2åˆ†é’Ÿ
            write=30.0,  # å†™å…¥è¶…æ—¶
            pool=60.0,  # è¿æ¥æ± è¶…æ—¶
        )
        self.client = httpx.AsyncClient(
            timeout=timeout_config,
            limits=httpx.Limits(max_connections=10, max_keepalive_connections=5),
        )

        # AutoGenå…¼å®¹æ€§å±æ€§
        self.model_info = {
            "vision": False,
            "function_calling": True,
            "json_output": True,
            "structured_output": True,
            "multiple_system_messages": True,
        }

    async def create(
        self,
        messages: List[Dict[str, Any]],
        model: Optional[str] = None,
        tools: Optional[List[Dict[str, Any]]] = None,
        tool_choice: Optional[str] = None,
        stream: bool = False,
        **kwargs,
    ) -> CreateResult:
        """
        AutoGenå…¼å®¹çš„createæ–¹æ³•
        """
        try:
            logger.info(
                f"ğŸ¯ Native Gemini Client - Creating completion for model: {model or self.model}"
            )
            logger.info(f"ğŸ“ Messages count: {len(messages)}")
            logger.info(f"ğŸ”§ Tools count: {len(tools) if tools else 0}")

            # è½¬æ¢æ ¼å¼
            gemini_request = self._convert_to_gemini_format(messages, tools)
            logger.info(
                f"ğŸ“¤ Converted to Gemini format: {json.dumps(gemini_request, indent=2)}"
            )

            # è°ƒç”¨Gemini API
            response_data = await self._call_gemini_api(
                gemini_request, model or self.model
            )
            logger.info(
                f"ğŸ“¥ Gemini API response: {json.dumps(response_data, indent=2, ensure_ascii=False)}"
            )

            # è½¬æ¢å›AutoGenæ ¼å¼
            autogen_response = self._convert_to_autogen_format(response_data, tools)
            logger.info(f"âœ… Converted to AutoGen format")

            return autogen_response

        except Exception as e:
            # æ›´è¯¦ç»†çš„é”™è¯¯å¤„ç†
            error_type = type(e).__name__
            if "ReadTimeout" in error_type or "TimeoutError" in error_type:
                logger.error(
                    f"âŒ Native Gemini Client timeout error: {error_type} - {e}"
                )
                raise Exception(
                    f"Gemini APIè¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚è¯¦ç»†é”™è¯¯: {error_type}"
                )
            elif "ConnectTimeout" in error_type:
                logger.error(
                    f"âŒ Native Gemini Client connection timeout: {error_type} - {e}"
                )
                raise Exception(
                    f"æ— æ³•è¿æ¥åˆ°Gemini APIï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚è¯¦ç»†é”™è¯¯: {error_type}"
                )
            else:
                logger.error(f"âŒ Native Gemini Client error: {error_type} - {e}")
                raise

    async def create_stream(
        self,
        messages: List[Dict[str, Any]],
        model: Optional[str] = None,
        tools: Optional[List[Dict[str, Any]]] = None,
        tool_choice: Optional[str] = None,
        **kwargs,
    ) -> AsyncGenerator[CreateResult, None]:
        """
        AutoGenå…¼å®¹çš„create_streamæ–¹æ³• - æµå¼å“åº”
        ç›®å‰ç®€åŒ–å®ç°ï¼šè°ƒç”¨éæµå¼APIå¹¶ä½œä¸ºå•ä¸ªchunkè¿”å›
        """
        try:
            logger.info(
                f"ğŸ¯ Native Gemini Client - Creating streaming completion for model: {model or self.model}"
            )

            # è°ƒç”¨éæµå¼createæ–¹æ³•
            result = await self.create(
                messages=messages,
                model=model,
                tools=tools,
                tool_choice=tool_choice,
                stream=False,
                **kwargs,
            )

            # ä½œä¸ºå•ä¸ªchunkè¿”å›
            yield result

        except Exception as e:
            # æ›´è¯¦ç»†çš„é”™è¯¯å¤„ç†
            error_type = type(e).__name__
            if "ReadTimeout" in error_type or "TimeoutError" in error_type:
                logger.error(
                    f"âŒ Native Gemini Client streaming timeout error: {error_type} - {e}"
                )
                raise Exception(
                    f"Gemini APIæµå¼è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚è¯¦ç»†é”™è¯¯: {error_type}"
                )
            elif "ConnectTimeout" in error_type:
                logger.error(
                    f"âŒ Native Gemini Client streaming connection timeout: {error_type} - {e}"
                )
                raise Exception(
                    f"æ— æ³•è¿æ¥åˆ°Gemini APIï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚è¯¦ç»†é”™è¯¯: {error_type}"
                )
            else:
                logger.error(
                    f"âŒ Native Gemini Client streaming error: {error_type} - {e}"
                )
                raise

    def _convert_to_gemini_format(
        self,
        messages: List[Dict[str, Any]],
        tools: Optional[List[Dict[str, Any]]] = None,
    ) -> Dict[str, Any]:
        """
        å°†OpenAIæ ¼å¼è½¬æ¢ä¸ºGeminiæ ¼å¼
        """
        contents = []

        for message in messages:
            # å¤„ç†AutoGençš„æ¶ˆæ¯å¯¹è±¡å’Œå­—å…¸ä¸¤ç§æ ¼å¼
            logger.info(f"ğŸ” Message type: {type(message)}, message: {message}")

            # ä½¿ç”¨try-exceptæ›´å®‰å…¨åœ°å¤„ç†ä¸åŒæ ¼å¼
            try:
                # å…ˆå°è¯•å­—å…¸æ ¼å¼
                if hasattr(message, "get") and callable(getattr(message, "get")):
                    # æ™®é€šå­—å…¸æ ¼å¼
                    logger.info(f"âœ… Using dict format")
                    role = message.get("role", "")
                    content = message.get("content", "")
                else:
                    # AutoGenæ¶ˆæ¯å¯¹è±¡ï¼ˆSystemMessage, UserMessage, AssistantMessageç­‰ï¼‰
                    logger.info(f"âœ… Using AutoGen message object format")
                    # AutoGenå¯¹è±¡ä½¿ç”¨typeå±æ€§è€Œä¸æ˜¯role
                    message_type = getattr(message, "type", "")
                    content = getattr(message, "content", "")

                    # å°†AutoGençš„typeæ˜ å°„åˆ°role
                    if message_type == "SystemMessage":
                        role = "system"
                    elif message_type == "UserMessage":
                        role = "user"
                    elif message_type == "AssistantMessage":
                        role = "assistant"
                    else:
                        # å°è¯•ä»sourceå±æ€§æ¨æ–­è§’è‰²
                        source = getattr(message, "source", "")
                        if source == "user":
                            role = "user"
                        else:
                            role = "assistant"
            except Exception as e:
                logger.error(f"âŒ Error processing message {message}: {e}")
                # å›é€€åˆ°å¯¹è±¡å±æ€§è®¿é—®
                message_type = getattr(message, "type", "")
                content = getattr(message, "content", "")

                # å°†AutoGençš„typeæ˜ å°„åˆ°role
                if message_type == "SystemMessage":
                    role = "system"
                elif message_type == "UserMessage":
                    role = "user"
                elif message_type == "AssistantMessage":
                    role = "assistant"
                else:
                    # å°è¯•ä»sourceå±æ€§æ¨æ–­è§’è‰²
                    source = getattr(message, "source", "")
                    if source == "user":
                        role = "user"
                    else:
                        role = "assistant"

            if role == "system":
                # ç³»ç»Ÿæ¶ˆæ¯ä½œä¸ºç¬¬ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯çš„å‰ç¼€
                if contents and contents[-1].get("role") == "user":
                    contents[-1]["parts"][0][
                        "text"
                    ] = f"{content}\n\n{contents[-1]['parts'][0]['text']}"
                else:
                    contents.append({"role": "user", "parts": [{"text": content}]})
            elif role == "user":
                contents.append({"role": "user", "parts": [{"text": content}]})
            elif role == "assistant":
                contents.append({"role": "model", "parts": [{"text": content}]})

        request_data = {"contents": contents}

        # å¤„ç†å·¥å…·è°ƒç”¨ - ä¿®å¤åçš„Gemini APIå…¼å®¹æ€§é€»è¾‘
        if tools:
            logger.info(f"ğŸ”§ Processing {len(tools)} tools for Gemini API")
            function_declarations = []

            for tool in tools:
                logger.info(f"ğŸ”§ Processing tool type: {type(tool)}, tool: {tool}")
                try:
                    # å¤„ç†AutoGen FunctionToolå¯¹è±¡
                    if (
                        hasattr(tool, "_func")
                        and hasattr(tool, "_name")
                        and hasattr(tool, "_description")
                    ):
                        # AutoGen FunctionToolå¯¹è±¡æ ¼å¼
                        tool_name = getattr(tool, "_name", "")
                        tool_description = getattr(tool, "_description", "")

                        # ä»å‡½æ•°ç­¾åè·å–å‚æ•°ä¿¡æ¯
                        import inspect

                        func = getattr(tool, "_func", None)
                        parameters = {
                            "type": "object",
                            "properties": {},
                            "required": [],
                        }

                        if func:
                            sig = inspect.signature(func)
                            for param_name, param in sig.parameters.items():
                                param_type = "string"  # é»˜è®¤ç±»å‹
                                if param.annotation != inspect.Parameter.empty:
                                    if param.annotation == int:
                                        param_type = "integer"
                                    elif param.annotation == float:
                                        param_type = "number"
                                    elif param.annotation == bool:
                                        param_type = "boolean"
                                    elif param.annotation == dict:
                                        param_type = "object"
                                    elif param.annotation == list:
                                        param_type = "array"

                                parameters["properties"][param_name] = {
                                    "type": param_type,
                                    "description": f"Parameter {param_name}",
                                }

                                if param.default == inspect.Parameter.empty:
                                    parameters["required"].append(param_name)

                        function_declarations.append(
                            {
                                "name": tool_name,
                                "description": tool_description,
                                "parameters": parameters,
                            }
                        )
                        logger.info(
                            f"âœ… Successfully processed FunctionTool: {tool_name}"
                        )

                    # å¤„ç†å­—å…¸æ ¼å¼çš„å·¥å…·å®šä¹‰
                    elif hasattr(tool, "get") and callable(getattr(tool, "get")):
                        if tool.get("type") == "function":
                            func = tool["function"]
                            function_declarations.append(
                                {
                                    "name": func["name"],
                                    "description": func["description"],
                                    "parameters": func.get(
                                        "parameters",
                                        {
                                            "type": "object",
                                            "properties": {},
                                            "required": [],
                                        },
                                    ),
                                }
                            )
                            logger.info(
                                f"âœ… Successfully processed dict tool: {func['name']}"
                            )

                    # å¤„ç†å…¶ä»–å¯èƒ½çš„å·¥å…·æ ¼å¼
                    elif hasattr(tool, "function_schema"):
                        schema = tool.function_schema
                        function_declarations.append(
                            {
                                "name": schema.get("name", ""),
                                "description": schema.get("description", ""),
                                "parameters": schema.get(
                                    "parameters",
                                    {
                                        "type": "object",
                                        "properties": {},
                                        "required": [],
                                    },
                                ),
                            }
                        )
                        logger.info(
                            f"âœ… Successfully processed schema tool: {schema.get('name', 'unknown')}"
                        )

                    else:
                        logger.warning(f"âš ï¸ Unknown tool format: {type(tool)}, skipping")

                except Exception as e:
                    logger.error(f"âŒ Error processing tool {tool}: {e}")
                    import traceback

                    traceback.print_exc()
                    continue

            # æ·»åŠ å·¥å…·å£°æ˜åˆ°è¯·æ±‚ä¸­
            if function_declarations:
                request_data["tools"] = [
                    {"functionDeclarations": function_declarations}
                ]
                logger.info(
                    f"âœ… Added {len(function_declarations)} function declarations to request"
                )
            else:
                logger.warning("âš ï¸ No valid function declarations found")

        return request_data

    async def _call_gemini_api(
        self,
        request_data: Dict[str, Any],
        model: str,
        max_retries: Optional[int] = None,
    ) -> Dict[str, Any]:
        """
        è°ƒç”¨GeminiåŸç”ŸAPI - ä½¿ç”¨v1betaç«¯ç‚¹æ”¯æŒfunction calling
        åŒ…å«é‡è¯•æœºåˆ¶ä»¥å¤„ç†ä¸´æ—¶è¶…æ—¶é”™è¯¯
        """
        if max_retries is None:
            max_retries = self.max_retries

        url = f"{self.base_url}/models/{model}:generateContent"

        params = {"key": self.api_key}
        headers = {"Content-Type": "application/json"}

        logger.info(f"ğŸŒ Calling Gemini API (v1beta): {url}")
        logger.info(
            f"ğŸ“¤ Request data: {json.dumps(request_data, indent=2, ensure_ascii=False)}"
        )

        last_error = None
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    # æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥
                    wait_time = 2**attempt
                    logger.info(f"ğŸ”„ é‡è¯•ç¬¬ {attempt + 1} æ¬¡ï¼Œç­‰å¾… {wait_time} ç§’...")
                    await asyncio.sleep(wait_time)

                response = await self.client.post(
                    url, json=request_data, params=params, headers=headers
                )

                if response.status_code != 200:
                    error_text = response.text
                    logger.error(
                        f"âŒ Gemini API error {response.status_code}: {error_text}"
                    )
                    raise Exception(
                        f"Gemini API error {response.status_code}: {error_text}"
                    )

                logger.info(f"âœ… Gemini APIè°ƒç”¨æˆåŠŸ (å°è¯• {attempt + 1}/{max_retries})")
                return response.json()

            except (
                httpx.ReadTimeout,
                httpx.ConnectTimeout,
                httpx.TimeoutException,
            ) as e:
                last_error = e
                error_type = type(e).__name__
                logger.warning(
                    f"âš ï¸ Gemini API timeout (å°è¯• {attempt + 1}/{max_retries}): {error_type} - {e}"
                )

                if attempt == max_retries - 1:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                    if isinstance(e, httpx.ReadTimeout):
                        logger.error(
                            f"âŒ Gemini API read timeout after {max_retries} attempts: {e}"
                        )
                        raise Exception(
                            "Gemini APIè¯»å–è¶…æ—¶ï¼Œå·²é‡è¯•å¤šæ¬¡ï¼Œè¯·æ±‚å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´å¤„ç†ï¼Œè¯·ç¨åé‡è¯•"
                        )
                    elif isinstance(e, httpx.ConnectTimeout):
                        logger.error(
                            f"âŒ Gemini API connect timeout after {max_retries} attempts: {e}"
                        )
                        raise Exception(
                            "è¿æ¥Gemini APIè¶…æ—¶ï¼Œå·²é‡è¯•å¤šæ¬¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
                        )
                    else:
                        logger.error(
                            f"âŒ Gemini API general timeout after {max_retries} attempts: {e}"
                        )
                        raise Exception("Gemini APIè¯·æ±‚è¶…æ—¶ï¼Œå·²é‡è¯•å¤šæ¬¡ï¼Œè¯·ç¨åé‡è¯•")

            except Exception as e:
                logger.error(f"âŒ Gemini API call failed: {type(e).__name__} - {e}")
                raise

        # è¿™é‡Œä¸åº”è¯¥åˆ°è¾¾ï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§
        if last_error:
            raise last_error
        else:
            raise Exception("æœªçŸ¥é”™è¯¯ï¼šæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")

    def _convert_to_autogen_format(
        self,
        gemini_response: Dict[str, Any],
        tools: Optional[List[Dict[str, Any]]] = None,
    ) -> CreateResult:
        """
        å°†Geminiå“åº”è½¬æ¢ä¸ºAutoGen CreateResultæ ¼å¼
        """
        candidates = gemini_response.get("candidates", [])
        if not candidates:
            raise Exception("No candidates in Gemini response")

        candidate = candidates[0]
        content = candidate.get("content", {})
        parts = content.get("parts", [])

        # æå–æ–‡æœ¬å†…å®¹
        message_content = ""
        function_calls = []

        for part in parts:
            if "text" in part:
                message_content += part["text"]
            elif "functionCall" in part:
                # å¤„ç†å·¥å…·è°ƒç”¨ - ä½¿ç”¨FunctionCallè€Œä¸æ˜¯FunctionExecutionResult
                func_call = part["functionCall"]
                function_calls.append(
                    FunctionCall(
                        id=f"call_{len(function_calls)}",
                        name=func_call.get("name", ""),
                        arguments=json.dumps(func_call.get("args", {})),
                    )
                )

        # æ„å»ºä½¿ç”¨ç»Ÿè®¡
        usage_metadata = gemini_response.get("usageMetadata", {})
        usage = {
            "prompt_tokens": usage_metadata.get("promptTokenCount", 0),
            "completion_tokens": usage_metadata.get("candidatesTokenCount", 0),
            "total_tokens": usage_metadata.get("totalTokenCount", 0),
        }

        # æ˜ å°„Geminiçš„finishReasonåˆ°AutoGenæœŸæœ›çš„å€¼
        finish_reason_map = {
            "STOP": "stop",
            "MAX_TOKENS": "length",
            "SAFETY": "content_filter",
            "RECITATION": "content_filter",
            "OTHER": "unknown",
        }

        gemini_finish_reason = candidate.get("finishReason", "STOP")
        finish_reason = finish_reason_map.get(gemini_finish_reason, "unknown")

        # å¦‚æœæœ‰å‡½æ•°è°ƒç”¨ï¼Œfinish_reasonåº”è¯¥æ˜¯function_calls
        if function_calls:
            finish_reason = "function_calls"

        # æ ¹æ®CreateResultçš„æœŸæœ›æ ¼å¼ï¼Œcontentåº”è¯¥æ˜¯å­—ç¬¦ä¸²æˆ–FunctionCallåˆ—è¡¨
        if function_calls:
            # å¦‚æœæœ‰å‡½æ•°è°ƒç”¨ï¼Œè¿”å›å‡½æ•°è°ƒç”¨åˆ—è¡¨
            result_content = function_calls
        else:
            # å¦‚æœåªæœ‰æ–‡æœ¬ï¼Œè¿”å›æ–‡æœ¬å†…å®¹
            result_content = message_content if message_content else "No response"

        # è¿”å›CreateResult
        return CreateResult(
            finish_reason=finish_reason,
            content=result_content,
            usage=usage,
            cached=False,
            logprobs=None,
        )

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.client.aclose()


# å…¨å±€å®¢æˆ·ç«¯ç¼“å­˜
_clients = {}


def get_native_gemini_client(
    model: str = "gemini-2.5-pro", read_timeout: float = 120.0, max_retries: int = 3
) -> NativeGeminiClient:
    """
    è·å–åŸç”ŸGeminiå®¢æˆ·ç«¯å®ä¾‹

    Args:
        model: Geminiæ¨¡å‹åç§°
        read_timeout: è¯»å–è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    """
    # ä½¿ç”¨æ¨¡å‹åç§°å’Œé…ç½®ä½œä¸ºç¼“å­˜key
    cache_key = f"{model}_{read_timeout}_{max_retries}"

    if cache_key not in _clients:
        _clients[cache_key] = NativeGeminiClient(
            model=model, read_timeout=read_timeout, max_retries=max_retries
        )
        logger.info(
            f"âœ… Created new native Gemini client for model: {model} (timeout: {read_timeout}s, retries: {max_retries})"
        )

    return _clients[cache_key]
